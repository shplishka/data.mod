<div dir="rtl">

## Data Aware Scheduling

כמו שאתם בוודאי יודעים, בAirflow אפשר לתזמן תהליכים לפי זמן, interval, בגרסה 2.4 נוספה אפשרות לתזמן לפי עדכון של Datasetים. נסביר.

מהם Datasetים בAirflow? ייצוג לוגי של מידע. Dataset הוא בגדול נתיב, בS3, HDFS, שמכיל מידע מסוים.

כדי להבין את השימוש,
נדמיין מקרה בו יש לנו 2 DAGים. האחד כותב לS3, והשני עובד על המידע שהDAG הראשון כותב לS3. אפשר לתזמן את הDAG השני על פי סיומו של הDAG הראשון אבל צריך לזכור שAirflow עצמו אינו פיזית כותב לS3, אלא מפבלש בקשת כתיבה, ומי שproper כותב לS3, הוא התשתית S3 עצמה בדרך כלל באופן אסינכרוני.

כלומר – סיומו של הDAG הראשון אינו בהכרח מעיד על נוכחות המידע בS3, לכן יכול להיות שיהיה מצב שהDAG הראשון יופעל, ולא יהיה לו מידע לעבוד עליו, לכן לכאורה "בזבזנו" הרצה שלמה של DAG.

מה נעשה אחרת באמצעות Data Aware Scheduling? נגדיר Dataset – הנתיב בS3 שאליו כותב הDAG הראשון, ונתזמן את הDAG השני לפי ההתעדכנות של הDataset. כך למעשה הDAG השני יופעל רק כאשר המידע כבר התעדכן בתשתית הS3 ולכן לא יוכל להיווצר מצב שבו ההרצה של הDAG השני תתבזבז.

<br/>

## DAG Owner Links
פיצ'ר שמתמקד יותר בQuality of life, כדי לנהל את הDAGים שלכם בצורה יותר טובה, תוכלו להוסיף לינקים לתיעוד שלכם/הסברים/הוראות הרצה כדי לאפשר שימור ידע בצורה טובה יותר.

דרך הUI של Airflow תוכלו ללחוץ על השם שנמצא בשדה של הבעלים, והוא ייקח אותם ללינק להוסיף לינקים לConfulence שלכם לדוגמה.
דוגמה:

![airflow-](/airflow-wasach/resources/dag-owner-links-example.png)

שימו ❤ בעתיד, ההגדרה של owner link תהיה חובה, נחייב את כל בעלי הDAGים לשים קישור לrepo, לconfluence ומייל של איש קשר במקרה הצורך בשביל לייצר אחיזה על מי אחראי על כל אחד מהתהליכים בקלאסטר.
 

<br/>

## Notifiers
BaseNotifier היא מחלקה אבסטרקטית שבאמצעותה משתמשים יכולים להגדיר Notifications משלהם בDAGים!

בAirflow, כמו בOozie אפשר להגדיר שתשלח התראה במקרה של כישלון. בשונה מOozie, אפשר להגדיר לAirflow לשלוח התראות במקרים אחרים חוץ מכישלון באמצעות callbacks לדוגמה (הטרגה של פעולה בנק' שונות במהלך הריצה של התהליך).

Airflow מיחצן כמה התראות בסיסיות ביניהן התראת מייל (כמו שאתם מכירים מאוזי). במקרה ויש לכם צורך בהתראה בהתאמה אישית – לדוגמה שליחת בקשה ל-API endpoint שלכם בעת כישלון הDAG, תוכלו לממש Notifier משלכם, שבעת כישלון ישלח בקשת http לendpoint מסוים.

נראה דוגמה למימוש של notifier בסיסי שבעת כישלון והצלחה של הDAG עושה פעולה מסוימת באמצעות שימוש בcallbacks:

https://tinyurl.com/airflow-notifications 

<br/>

## Grid View Improvements
אם יצא לכם להסתכל לאחרונה בUI של Airflow ביחידה, בפרט בחלק של הGrid View בDAG, בטח חשבתם לעצמכם "אנחנו לא בשלב מספיק מאוחר בהיסטוריה האנושית כדי שהDAG שלי יוצג קצת יותר באסתטיות מאשר סתם קוביות חסרות נשמה וחצים?" לא? רק אני?

בכל מקרה, בAirflow 2.6 שידרגו את Grid View ועכשיו, במקום הקוביות חסרות הנשמה, יש View מודרני שהרבה יותר נוח ואינטואיטיבי לקרוא.
אפשר לצמצם גם את הטווח הצגה של הGrid (בשפה מקצועיתfilter downstream/upstream).

![airflow-improved-grid-view](/airflow-wasach/resources/improved-grid-view.png)
 

<br/>

## Greatly Improved Dag.test()
באמצעות הפקודה dag.test() נוכל לדבג הרצה של DAG בIDE שלנו! עכשיו נוכל גם להעביר ארגומנטים, בשביל לסמלץ מקרי קצה וקונפיגורציות ריצה ספציפיות.

כל הטוב הזה ירוץ לנו לוקאלית על המחשב בpython process אחד, פניות לשירותים חיצוניים כמו DBs לא יעבדו, אבל אתם רוצים לבדוק את הflow של הDAG שלכם, את הלוגיקה שלו, ולא את התפקוד של השירותים החיצוניים.

כאשר תריצו את הפקודה dag.test() לוקאלית שירותים חיצוניים ממוסכים לכם (כאילו עשיתם להם mock) ואתם יכולים לבדוק את לוגיקת הDAG שלכם בשקט.

נ.ב: לחוששים, כן, גם הלוגים של הDAG נמצאים לכם ישר בIDE terminal :).

<br/>

## Auto Refresh on the Home Page
אתם נמצאים בDAG שלכם ורואים את הנתונים מתעדכנים לכם מול העיניים בזמן אמת - זמן הריצה, הtaskים שצלחו ואלו שפחות, לוגים וכו'.

החיים יפים, אתם שותים לכם לימונענע על החוף באיביזה, ופותחים את הטאב של מסך הבית ונמלאים חרדה – אתם רואים שהDAG שלכם בכלל לא רץ, וכל מה שראיתם בDAG page היה שקר מוחלט. אתם לוחצים F5 אינסטינקטיבית וחוזר לכם הדופק כשאתם רואים שהמסך פשוט לא היה מעודכן.

כדי לפתור את המשתמשים מטלטלת הרגשות הזאת Airflow החליטו לממש את אותו המנגנון שיש בDAG page גם במסך הבית. תודה באמת.
 

<br/>

## Defferable Operators
בשונה מOperatorים רגילים, Defferable operators עושים שימוש בספריית הasyncio של פייתון, מה שמאפשר להם להריץ taskים בצורה אסינכרונית. אסביר.

קודם נצטרך להבין איך עובדים Poolים בAirflow. בAirflow בריכות הם סביבות ריצה לתהליכים. בכל בריכה יש slotים שtaskים משתבצים אליהם, רק כשtask מצליחה למצוא slot בpool, היא יכולה להתחיל לרוץ, דמיינו את זה כמו הקצאת משאבים.

נמשיך בדמיון המודרך, ונדמיין DAG שמבצע Spark Job, בגלל שאנחנו תותחי Airflow אנחנו יודעים שAirflow אינה תשתית עיבוד, אלא תזמון, ולכן הביצוע הוא למעשה שליחת העבודה החוצה – למערכת חיצונית, סביבת הריצה של הSpark שלנו במקרה הזה. במהלך השהייה של העבודה אי שם בסביבת העבודה Airflow מן הסתם ממשיך לנתר עליה כדי לבדוק סטטוס הצלחה/כשלון/התקדמות – בטרמינולוגיה הAirflowית, Polling.

בזמן הזה, בו הJob נמצא בסביבת הSpark, הAirflow לא באמת מבצע עבודה משמעותית, כמו שאמרנו, הוא רק מנתר על הסטטוס שלה. לכן למה שהעבודה תמשיך לתפוס slot בpool? הרי היא לא באמת מבצעת עבודה משמעותית.

גם בAirflow הבינו זאת, ולכן יצאו עם קונספט חדש של operatorים אסינכרוניים! עכשיו, במקום שהtask תמשיך לתפוס slot גם בשלב הpolling, הslot יתפנה, הניתור על הtask יהיה אסינכרוני ובזמן הזה taskים אחרים יוכלו לתפוס את הslot ולרוץ, שיפור מטורף!

<br/>

## Open Telemetry
בAirflow, טרם לגרסה 2.7, Observability היו עושים באמצעות ספרייה שנקראת StatsD.
בפורום שיפורים של Airflow יצאה הצעה להכניס את OpenTelemetry בתמיכה native לתוך Airflow. וכך היה.

כעת, אפשר להשתמש בOpenTelemetry כדי לקבל מבט לתוך הpipelineים שלכם ולראות כיצד חלקים שונים שלהן מתקשרים ומדברים האחד עם השני בזמן אמת.
אם תרצו לקרוא עוד:
https://tinyurl.com/airflow-opentelemetry
 

<br/>

## Open Lineage
Data Lineage הוא הקונספט של מעקב וויזואליזציה של מידע מהמקור שלו לאיפה שהוא זורם ונצרך.

Open lineage הוא מוצר שהפך פחות או יותר לסטנדרט בחוץ בעולם הData lineage. מאפשר אסיפה של data lineage metadata בקלות וביעילות.

למה שתרצו בכלל Data lineage בAirflow? בשימוש בOpen Lineage עם Airflow, תוכלו להבין יותר טוב איך מסלול הזרימה של data pipeline שלכם עובד, מה שיכול לסייע לכם בייעול התהליכים שלכם, BI ו-Data Governance.

Airflow הוא בדיוק המקום להחיל data lineage, וזאת בשל שpipelineים שנבנים באמצעותו בדר"כ נוגעים בהרבה מאוד מאגרי מידע בשלל מקומות בארגון שהסביבה רצה עליו.

דוגמאות פרקטיות לשימושים שיכולים להיות לכם:
-	זיהוי מקור כישלונות תהליכים בהסתכלות על מקורות מידע שנמצאים במעלה הזרם (upstream).
-	ויזואליזציה של השפעות בין תהליכים – איך כשלון של תהליך א' משפיע על הריצה של תהליך ב'.
-	תיעדוף מקורות – נוכל לראות איזה מידע נמצא בשימוש הכי הרבה ואיזה פחות.

<br/>

## Dynamic Task Mapping
Dynamic task mapping הוא פיצ'ר ברמת Airflow, שמאפשר לDAG ליצור כמות דינאמית של taskים בהתאם להיקף העבודה שהוא צריך לבצע.

כך, כותב הDAG לא צריך לשערך מראש את כמות הtaskים שהוא צריך ליצור בDAG. כמו אתחול של taskים בתוך לולאה, אבל לא צריך לממש את הלוגיקה ברמת הDAG, היא קוראת ברמת התשתית – הscheduler של Airflow, בהתבסס על הפלט של taskים קודמים.

לפני שtask שהוחלה דינאמית מתבצעת הscheduler ייצור N העתקים של הtask המדובר, בהתאם לסד"ג של העבודה שהן צריכות לבצע.
דמיינו שיש לכם תהליך שעובד על כמות מסוימת של מידע, מbenchmarkים שעשיתם, ראיתם שהתהליך שלכם רץ הכי טוב על 10000 רשומות עם כמות משאבים מסוימת, אתם לא יודעים מה גודל המידע שיהיה לכם בכל פעם שהתהליך שלכם ירוץ ולכן אתם בכל פעם תצטרכו לדגום את גודל המידע ידנית בעצמכם מתוך הDAG ולייצר את הtaskים שלכם בלולאה כדי לעמוד בעומס, lame.

במקום, אתם יכולים להיות תותחי Airflow אמיתיים וליצור באמצעות dynamic task mapping כמה taskים שצריך בהתאם להיקף המידע!
לא משנה כמה נדבר על הפיצ'ר הזה, לא נעשה איתו צדק, לכן אני מפציר בכם לקרוא עליו עוד. סיכוי טוב מאוד שהוא מאוד רלוונטי אליכם ויכול לחסוך לכם הרבה כאבי ראש בתהליכים שמתמודדים עם עומסים משתנים ושחווים spikeים בזמני ריצה בהתאם.
תוכלו להרחיב עליו בלינק הבא:
https://tinyurl.com/airflow-dynamic-task-mapping

</div>